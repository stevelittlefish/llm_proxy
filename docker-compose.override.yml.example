version: '3.8'

services:
  llm-proxy:
    ports:
      - 11435:11434
      # To avoid conflicts with local ollama instance use this instead:
      # - 11435:11434
    volumes:
      # Mount config file
      - ./config.toml:/app/config/config.toml:ro
      # Mount database directory (allows persistence)
      - ./data:/app/data
